{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import tensorflow_io as tfio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Ingest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_and_resample(input_file: str, output_file: str):\n",
    "    \"\"\"\n",
    "    Converts an audio file to WAV format and resamples it to 16 kHz.\n",
    "    Skips conversion if the output file already exists.\n",
    "\n",
    "    Args:\n",
    "        input_file (str): Path to the input audio file (e.g., .ogg, .mp3).\n",
    "        output_file (str): Path to save the converted and resampled .wav file.\n",
    "    \"\"\"\n",
    "    print(\"start conversion\")\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"Skipped (already exists): {output_file}\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # Load the input audio file\n",
    "        audio = AudioSegment.from_file(input_file)\n",
    "        #set quantisation\n",
    "        audio_quant16 = audio.set_sample_width(2)  # 2 bytes = 16 bit\n",
    "        # Resample to 16 kHz\n",
    "        audio_16k = audio_quant16.set_frame_rate(16000)\n",
    "        # Export as .wav\n",
    "        audio_16k.export(output_file, format=\"wav\")\n",
    "        print(f\"Conversion and resampling successful: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during conversion and resampling: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_convert_and_resample(input_root, output_root, convert_and_resample, max_folders=None):\n",
    "    \"\"\"\n",
    "    Walk through input_root, find all .ogg files, and convert them to .wav\n",
    "    in output_root with the same folder structure.\n",
    "    \n",
    "    Parameters:\n",
    "        input_root (str): Path to the root folder containing .ogg files.\n",
    "        output_root (str): Path where converted .wav files will be saved.\n",
    "        convert_and_resample (func): Function that takes (in_path, out_path).\n",
    "        max_folders (int, optional): If set, only process the first N subfolders.\n",
    "    \"\"\"\n",
    "    # List top-level subfolders in input_root\n",
    "    subfolders = sorted(\n",
    "        [os.path.join(input_root, d) for d in os.listdir(input_root) \n",
    "         if os.path.isdir(os.path.join(input_root, d))]\n",
    "    )\n",
    "    print(\"start conversion\")\n",
    "    # Limit to first N folders if requested\n",
    "    if max_folders is not None:\n",
    "        subfolders = subfolders[:max_folders]\n",
    "\n",
    "    for folder in subfolders:\n",
    "        for dirpath, _, filenames in os.walk(folder):\n",
    "            for filename in filenames:\n",
    "                if filename.lower().endswith(\".ogg\") or filename.lower().endswith(\".wav\"):\n",
    "                    in_path = os.path.join(dirpath, filename)\n",
    "                    \n",
    "                    # Build matching output path\n",
    "                    rel_path = os.path.relpath(in_path, input_root)\n",
    "                    rel_path_no_ext = os.path.splitext(rel_path)[0] + \".wav\"\n",
    "                    out_path = os.path.join(output_root, rel_path_no_ext)\n",
    "\n",
    "                    # Ensure output directory exists\n",
    "                    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "\n",
    "                    # Convert\n",
    "                    convert_and_resample(in_path, out_path)\n",
    "                    print(f\"Converted: {in_path} -> {out_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_root = \"../data/birdclef-2024/train_audio\"\n",
    "# output_root = \"../data/birdclef-2024/train_audio_16\"\n",
    "\n",
    "# batch_convert_and_resample(input_root, output_root, convert_and_resample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train meta data\n",
    "train_metadata_path = \"../data/birdclef-2024/train_metadata.csv\"\n",
    "train_df = pd.read_csv(train_metadata_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df[\"rating\"].info()\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644cca9",
   "metadata": {},
   "source": [
    "### Read wav bird data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f80fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train meta data\n",
    "base_data_path = \"../data/birdclef-2024\"\n",
    "bird_metadata_path = os.path.join(base_data_path, \"train_metadata.csv\")\n",
    "bird_df = pd.read_csv(bird_metadata_path)\n",
    "\n",
    "# Display the first few rows of the dataframe\n",
    "bird_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857f4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Change the filename endings from .ogg to .wav in the filename column of bird_df\n",
    "bird_df['filename'] = bird_df['filename'].str.replace('.ogg', '.wav', regex=False)\n",
    "# Display the first few rows of the dataframe\n",
    "bird_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f064fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "# # Show rows where the filename matches the pattern \"cohcuc1/*.wav\"\n",
    "# bird_df[bird_df['filename'].str.startswith('cohcuc1/') & bird_df['filename'].str.endswith('.wav')].head()\n",
    "wav_files = glob.glob(base_data_path + \"/train_audio_16/**/*.wav\", recursive=True)\n",
    "wav_files = [f.replace(base_data_path + \"/train_audio_16/\", \"\") for f in wav_files]\n",
    "\n",
    "filtered_bird_df = bird_df[bird_df['filename'].isin(wav_files)]\n",
    "\n",
    "bird_classes = list(set(filtered_bird_df['common_name']))\n",
    "\n",
    "map_class_to_id = {name: idx for idx, name in enumerate(bird_classes)}\n",
    "\n",
    "# filtered_pd = pd_data[pd_data.category.isin(my_classes)]\n",
    "\n",
    "class_id = filtered_bird_df['common_name'].apply(lambda name: map_class_to_id[name])\n",
    "filtered_bird_df = filtered_bird_df.assign(target=class_id)\n",
    "\n",
    "\n",
    "full_path = filtered_bird_df['filename'].apply(lambda row: os.path.join(base_data_path + \"/train_audio_16/\", row))\n",
    "filtered_bird_df = filtered_bird_df.assign(filename=full_path)\n",
    "\n",
    "filtered_bird_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70edf93c",
   "metadata": {},
   "source": [
    "### Split data into training, validation and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46111e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df_idx, temp_df_idx = train_test_split(filtered_bird_df.index, test_size=0.4, random_state=42, stratify=filtered_bird_df['target'])\n",
    "\n",
    "val_df_idx, test_df_idx = train_test_split(temp_df_idx, test_size=0.5, random_state=42, stratify=filtered_bird_df.loc[temp_df_idx, 'target'])\n",
    "\n",
    "# Step 3: Create 'fold' column in original filtered_bird_df\n",
    "filtered_bird_df['fold'] = ''  # initialize empty\n",
    "filtered_bird_df.loc[train_df_idx, 'fold'] = 1\n",
    "filtered_bird_df.loc[val_df_idx, 'fold'] = 2\n",
    "filtered_bird_df.loc[test_df_idx, 'fold'] = 3\n",
    "\n",
    "filtered_bird_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2a4eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(filtered_bird_df[filtered_bird_df['fold'] == 1]['target'], bins=len(bird_classes), alpha=0.7, label='Train')\n",
    "plt.hist(filtered_bird_df[filtered_bird_df['fold'] == 2]['target'], bins=len(bird_classes), alpha=0.7, label='Val')\n",
    "plt.hist(filtered_bird_df[filtered_bird_df['fold'] == 3]['target'], bins=len(bird_classes), alpha=0.7, label='Test')\n",
    "plt.xlabel('Bird Classes')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Bird Classes in Train, Val, and Test Sets')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8f8fcc",
   "metadata": {},
   "source": [
    "Plot one waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c79600e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    \"\"\" Load a WAV file, convert it to a float tensor, resample to 16 kHz single-channel audio. \"\"\"\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    print(file_contents)\n",
    "    wav, sample_rate = tf.audio.decode_wav(\n",
    "          file_contents,\n",
    "          desired_channels=1)\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    \n",
    "    #sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    #wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8485151",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(x_train[0])\n",
    "# wav = load_wav_16k_mono(x_train[0])\n",
    "# plt.plot(wav)\n",
    "#plt.plot(testing_wav_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model.\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "#### Model inference / Create Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train = filtered_bird_df[filtered_bird_df['fold'] == 1]['filename']\n",
    "targets_train = filtered_bird_df[filtered_bird_df['fold'] == 1]['target']\n",
    "\n",
    "filenames_val = filtered_bird_df[filtered_bird_df['fold'] == 2]['filename']\n",
    "targets_val = filtered_bird_df[filtered_bird_df['fold'] == 2]['target']\n",
    "\n",
    "filenames_test = filtered_bird_df[filtered_bird_df['fold'] == 3]['filename']\n",
    "targets_test = filtered_bird_df[filtered_bird_df['fold'] == 3]['target']\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((filenames_train, targets_train))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((filenames_val, targets_val))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((filenames_test, targets_test))\n",
    "\n",
    "def load_wav_for_map(filename, label):\n",
    "  return load_wav_16k_mono(filename), label\n",
    "\n",
    "train_ds = train_ds.map(load_wav_for_map)\n",
    "val_ds = val_ds.map(load_wav_for_map)\n",
    "test_ds = test_ds.map(load_wav_for_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e8f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding(wav_data, label):\n",
    "  ''' run YAMNet to extract embedding from the wav data '''\n",
    "  scores, embeddings, spectrogram = model(wav_data)\n",
    "  num_embeddings = tf.shape(embeddings)[0]\n",
    "  return (embeddings,\n",
    "            tf.repeat(label, num_embeddings))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.map(extract_embedding).unbatch()\n",
    "val_ds = val_ds.map(extract_embedding).unbatch()\n",
    "test_ds = test_ds.map(extract_embedding).unbatch()\n",
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8299ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "#### Model classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_class_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Input(shape=(1024,), dtype=tf.float32,\n",
    "                          name='embedding'),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # 3 Klassen\n",
    "])\n",
    "\n",
    "bird_class_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782018d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_class_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a265bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = bird_class_model.fit(train_ds,\n",
    "                       epochs=20,\n",
    "                       validation_data=val_ds,\n",
    "                       callbacks=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0072c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = bird_class_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e826f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = load_wav_16k_mono(filtered_bird_df[filtered_bird_df['fold'] == 3]['filename'].values[0])\n",
    "scores, embeddings, spectrogram = model(wav)\n",
    "result = bird_class_model(embeddings).numpy()\n",
    "\n",
    "inferred_class = bird_classes[result.mean(axis=0).argmax()]\n",
    "print(f'The main sound is: {inferred_class}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
