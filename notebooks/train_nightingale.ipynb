{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "51bf9b14",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac694b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nightingale.model.classifier_head import ClassifierHead\n",
    "from nightingale.data.wav_loader import load_wav_16k_mono\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8ab77",
   "metadata": {},
   "source": [
    "### Load and Explore birdclef-2024 data (pre conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1137cde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train meta data\n",
    "train_metadata_path = \"../data/birdclef-2024/train_metadata.csv\"\n",
    "train_df = pd.read_csv(train_metadata_path)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857d0e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecb1492",
   "metadata": {},
   "source": [
    "### Prepare dataframe pointing to bird call audio data in wav format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba8473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read train meta data\n",
    "base_data_path = \"../data/birdclef-2024\"\n",
    "bird_metadata_path = os.path.join(base_data_path, \"train_metadata.csv\")\n",
    "bird_df = pd.read_csv(bird_metadata_path)\n",
    "\n",
    "# Change the filename endings from .ogg to .wav in the filename column of bird_df\n",
    "bird_df['filename'] = bird_df['filename'].str.replace('.ogg', '.wav', regex=False)\n",
    "\n",
    "# Show rows where the filename matches the pattern \"cohcuc1/*.wav\"\n",
    "wav_files = glob.glob(base_data_path + \"/train_audio_16/**/*.wav\", recursive=True)\n",
    "wav_files = [f.replace(base_data_path + \"/train_audio_16/\", \"\") for f in wav_files]\n",
    "\n",
    "filtered_bird_df = bird_df[bird_df['filename'].isin(wav_files)]\n",
    "\n",
    "bird_classes = list(set(filtered_bird_df['common_name']))\n",
    "\n",
    "map_class_to_id = {name: idx for idx, name in enumerate(bird_classes)}\n",
    "\n",
    "class_id = filtered_bird_df['common_name'].apply(lambda name: map_class_to_id[name])\n",
    "filtered_bird_df = filtered_bird_df.assign(target=class_id)\n",
    "\n",
    "full_path = filtered_bird_df['filename'].apply(lambda row: os.path.join(base_data_path + \"/train_audio_16/\", row))\n",
    "filtered_bird_df = filtered_bird_df.assign(filename=full_path)\n",
    "\n",
    "# filtered_bird_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2288298d",
   "metadata": {},
   "source": [
    "### Split data: Training, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade4a54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Split the data into training (60%), validation (20%) and test (20%) sets\n",
    "train_df_idx, temp_df_idx = train_test_split(filtered_bird_df.index, test_size=0.4, random_state=42, stratify=filtered_bird_df['target'])\n",
    "val_df_idx, test_df_idx = train_test_split(temp_df_idx, test_size=0.5, random_state=42, stratify=filtered_bird_df.loc[temp_df_idx, 'target'])\n",
    "\n",
    "# Step 2: Create 'fold' column in original filtered_bird_df\n",
    "filtered_bird_df['fold'] = ''  # initialize empty\n",
    "filtered_bird_df.loc[train_df_idx, 'fold'] = 1\n",
    "filtered_bird_df.loc[val_df_idx, 'fold'] = 2\n",
    "filtered_bird_df.loc[test_df_idx, 'fold'] = 3\n",
    "\n",
    "# filtered_bird_df.head(10)\n",
    "# plt.hist(filtered_bird_df[filtered_bird_df['fold'] == 1]['target'], bins=len(bird_classes), alpha=0.7, label='Train')\n",
    "# plt.hist(filtered_bird_df[filtered_bird_df['fold'] == 2]['target'], bins=len(bird_classes), alpha=0.7, label='Val')\n",
    "# plt.hist(filtered_bird_df[filtered_bird_df['fold'] == 3]['target'], bins=len(bird_classes), alpha=0.7, label='Test')\n",
    "# plt.xlabel('Bird Classes')\n",
    "# plt.ylabel('Count')\n",
    "# plt.title('Distribution of Bird Classes in Train, Val, and Test Sets')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9721db5e",
   "metadata": {},
   "source": [
    "### Modelling\n",
    "* Load YAMNet\n",
    "* Create audio/bird call embeddings using the training data with YAMNet\n",
    "* Create a custom classifier for bird call classification\n",
    "* Train classifier with created YAMNet embeddings (as inputs) and bird classes (as outputs)\n",
    "* Concatenate YAMNet and classifier and measure performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b9d79b",
   "metadata": {},
   "source": [
    "#### Load YAMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba052c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model.\n",
    "model = hub.load('https://tfhub.dev/google/yamnet/1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87803764",
   "metadata": {},
   "source": [
    "#### Use bird call audio to extract embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a647265",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames_train = filtered_bird_df[filtered_bird_df['fold'] == 1]['filename']\n",
    "targets_train = filtered_bird_df[filtered_bird_df['fold'] == 1]['target']\n",
    "\n",
    "filenames_val = filtered_bird_df[filtered_bird_df['fold'] == 2]['filename']\n",
    "targets_val = filtered_bird_df[filtered_bird_df['fold'] == 2]['target']\n",
    "\n",
    "filenames_test = filtered_bird_df[filtered_bird_df['fold'] == 3]['filename']\n",
    "targets_test = filtered_bird_df[filtered_bird_df['fold'] == 3]['target']\n",
    "\n",
    "\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((filenames_train, targets_train))\n",
    "val_ds = tf.data.Dataset.from_tensor_slices((filenames_val, targets_val))\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((filenames_test, targets_test))\n",
    "\n",
    "def load_wav_for_map(filename, label):\n",
    "  return load_wav_16k_mono(filename), label\n",
    "\n",
    "train_ds = train_ds.map(load_wav_for_map)\n",
    "val_ds = val_ds.map(load_wav_for_map)\n",
    "test_ds = test_ds.map(load_wav_for_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c181bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_embedding(wav_data, label):\n",
    "  ''' run YAMNet to extract embedding from the wav data '''\n",
    "  scores, embeddings, spectrogram = model(wav_data)\n",
    "  num_embeddings = tf.shape(embeddings)[0]\n",
    "  return (embeddings,\n",
    "            tf.repeat(label, num_embeddings))\n",
    "\n",
    "train_ds = train_ds.map(extract_embedding).unbatch()\n",
    "val_ds = val_ds.map(extract_embedding).unbatch()\n",
    "test_ds = test_ds.map(extract_embedding).unbatch()\n",
    "train_ds.element_spec\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.cache().batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e463070",
   "metadata": {},
   "source": [
    "#### Model bird call classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb0ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bird_classes = len(bird_classes)\n",
    "bird_class_model = ClassifierHead(num_classes=num_bird_classes)\n",
    "\n",
    "bird_class_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c44c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "bird_class_model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                 optimizer=\"adam\",\n",
    "                 metrics=['accuracy'])\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                            patience=3,\n",
    "                                            restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d74237",
   "metadata": {},
   "source": [
    "#### Configure MLFLow Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5010b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "client = MlflowClient(tracking_uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "experiment_description = (\n",
    "    \"Nightingale is a bird call classification project.\"\n",
    ")\n",
    "\n",
    "experiment_tags = {\n",
    "    \"project_name\": \"nightingale\",\n",
    "    \"mlflow.note.content\": experiment_description,\n",
    "}\n",
    "\n",
    "# only run following command once to create the experiment after the server has been started for the first time\n",
    "# client.create_experiment(name=\"Nightingale_Bird_Call_Classification\", tags=experiment_tags)\n",
    "\n",
    "# Use the fluent API to set the tracking uri and the active experiment\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Sets the current active experiment to the \"Nightingale_Bird_Call_Classification\" experiment and returns the Experiment metadata\n",
    "nightingale_experiment = mlflow.set_experiment(\"Nightingale_Bird_Call_Classification\")\n",
    "\n",
    "# Define a run name for this iteration of training.\n",
    "# If this is not set, a unique name will be auto-generated for your run.\n",
    "run_name = \"nightingale_classifier_test\"\n",
    "\n",
    "# Define an artifact path that the model will be saved to.\n",
    "artifact_path = \"classifier_nightingale\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9fd460",
   "metadata": {},
   "source": [
    "#### Train classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0dd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = bird_class_model.fit(train_ds,\n",
    "                       epochs=20,\n",
    "                       validation_data=val_ds,\n",
    "                       callbacks=callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1a7959",
   "metadata": {},
   "source": [
    "#### Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfe1437",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = bird_class_model.evaluate(test_ds)\n",
    "\n",
    "print(\"Loss: \", loss)\n",
    "print(\"Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd2dcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble the metrics we're going to write into a collection\n",
    "metrics = {\"Loss\": loss, \"Accuracy\": accuracy}\n",
    "params = {\n",
    "    \"num_bird_classes\": num_bird_classes,\n",
    "    \"optimizer\": \"adam\",\n",
    "    \"loss_function\": \"SparseCategoricalCrossentropy\",\n",
    "    \"loss_from_logits\": True,\n",
    "    \"epochs\": len(history.epoch),\n",
    "    \"batch_size\": 32,\n",
    "    \"early_stopping_monitor\": \"loss\",\n",
    "    \"early_stopping_patience\": 3,\n",
    "}\n",
    "\n",
    "# Initiate the MLflow run context\n",
    "with mlflow.start_run(run_name=run_name) as run:\n",
    "    # Log the parameters used for the model fit\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the error metrics that were calculated during validation\n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # Take one batch from the dataset\n",
    "    x_batch, y_batch = next(iter(train_ds))\n",
    "\n",
    "    # Convert to numpy (MLflow expects numpy or tensor-like input, not a tf.data.Dataset)\n",
    "    input_example = x_batch.numpy()\n",
    "\n",
    "    print(\"Shape of input_example:\", input_example.shape)\n",
    "    # Log an instance of the trained model for later use\n",
    "    mlflow.tensorflow.log_model(model=bird_class_model, input_example=input_example, name=artifact_path)\n",
    "    # mlflow.sklearn.log_model(sk_model=rf, input_example=X_val, name=artifact_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bfd89f",
   "metadata": {},
   "source": [
    "#### Run inference on a bird call audio sample (YAMNet + classifier head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34dc830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav = load_wav_16k_mono(filtered_bird_df[filtered_bird_df['fold'] == 3]['filename'].values[1])\n",
    "scores, embeddings, spectrogram = model(wav)\n",
    "result = bird_class_model(embeddings).numpy()\n",
    "\n",
    "inferred_class = bird_classes[result.mean(axis=0).argmax()]\n",
    "print(f'The main sound is: {inferred_class}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
